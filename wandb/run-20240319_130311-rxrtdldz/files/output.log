epoch 0,  actor_loss: 53.8574,  critic_loss: 3.2572, cost_time: 2.5062, best_solution: 0,od: 1.3791, eqity: 2.3689,rad: 19.0322
1.3791461873333901 2.3689456805586815 19.032193660736084
epoch 1,  actor_loss: 64.6194,  critic_loss: 5.5196, cost_time: 1.7197, best_solution: [10.502609252929688],od: 2.1951, eqity: 4.2070,rad: 18.3378
2.1951243048533797 4.207022435963154 18.337841987609863
epoch 2,  actor_loss: -65.7739,  critic_loss: 4.1742, cost_time: 2.7255, best_solution: [10.8700532913208],od: 5.7418, eqity: 5.6892,rad: 26.3532
5.741800869000144 5.689186483621597 26.3532235622406
epoch 3,  actor_loss: -31.9709,  critic_loss: 4.4064, cost_time: 1.6361, best_solution: [16.031726837158203],od: 2.0736, eqity: 3.5008,rad: 10.6628
epoch 4,  actor_loss: 27.3499,  critic_loss: 1.3059, cost_time: 1.9993, best_solution: [16.031726837158203],od: 2.5065, eqity: 4.5030,rad: 19.0322
epoch 5,  actor_loss: -9.5437,  critic_loss: 0.3434, cost_time: 1.6699, best_solution: [16.031726837158203],od: 0.3504, eqity: 0.9349,rad: 6.8686
epoch 6,  actor_loss: 19.7674,  critic_loss: 0.7500, cost_time: 1.9633, best_solution: [16.031726837158203],od: 1.1091, eqity: 2.0223,rad: 13.7312
epoch 7,  actor_loss: 38.6736,  critic_loss: 1.7912, cost_time: 2.2930, best_solution: [16.031726837158203],od: 3.3213, eqity: 3.7859,rad: 22.3924
epoch 8,  actor_loss: 33.5709,  critic_loss: 1.5859, cost_time: 1.8485, best_solution: [16.031726837158203],od: 3.8504, eqity: 4.6072,rad: 18.1553
epoch 9,  actor_loss: -4.7750,  critic_loss: 1.1288, cost_time: 2.3450, best_solution: [16.031726837158203],od: 3.2516, eqity: 4.2009,rad: 22.2098
epoch 10,  actor_loss: -6.5637,  critic_loss: 1.2186, cost_time: 2.0211, best_solution: [16.031726837158203],od: 2.4561, eqity: 4.3287,rad: 21.8403
epoch 11,  actor_loss: 14.3029,  critic_loss: 0.6183, cost_time: 2.2731, best_solution: [16.031726837158203],od: 4.3326, eqity: 5.3452,rad: 25.8948
epoch 12,  actor_loss: 19.8175,  critic_loss: 1.9275, cost_time: 2.5150, best_solution: [16.031726837158203],od: 5.6826, eqity: 5.5858,rad: 24.6755
epoch 13,  actor_loss: -18.6092,  critic_loss: 2.1881, cost_time: 1.8045, best_solution: [16.031726837158203],od: 1.0934, eqity: 3.5599,rad: 13.7312
Traceback (most recent call last):
  File "/home/liqing/MORL/Metro-Line/metro.py", line 773, in <module>
    train_vrp(args)
  File "/home/liqing/MORL/Metro-Line/metro.py", line 646, in train_vrp
    train(actor, critic, allowed_station, static_size=STATIC_SIZE, **kwargs)
  File "/home/liqing/MORL/Metro-Line/metro.py", line 298, in train
    tour_idx, tour_logp = actor(static, dynamic, allowed_station,  args.station_num_lim, args.first, args.budget, args.initial_direct, args.line_unit_price, args.station_price, decoder_input=None, last_hh=None)
  File "/home/liqing/anaconda3/envs/morl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/liqing/anaconda3/envs/morl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liqing/MORL/Metro-Line/metro_model.py", line 377, in forward
    self.direction_vector, vector_index_allow = self.vector_allow_fn(agent_current_index, grid_index1, exist_agent_last_grid, self.direction_vector)
  File "/home/liqing/MORL/Metro-Line/metro_vrp.py", line 631, in vector_allow
    direction_vector = self.agent_direct_vector(direction_vector, grid_index1, exist_agent_last_grid)
  File "/home/liqing/MORL/Metro-Line/metro_vrp.py", line 479, in agent_direct_vector
    elif torch.equal(deviation2, self.quadrant3):
KeyboardInterrupt